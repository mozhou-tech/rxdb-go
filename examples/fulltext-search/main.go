package main

import (
	"context"
	"fmt"
	"log"
	"os"

	"github.com/mozy/rxdb-go/pkg/rxdb"
)

func main() {
	ctx := context.Background()

	// åˆ›å»ºæ•°æ®åº“
	db, err := rxdb.CreateDatabase(ctx, rxdb.DatabaseOptions{
		Name: "fulltext-demo",
		Path: "./fulltext-demo.db",
	})
	if err != nil {
		log.Fatalf("Failed to create database: %v", err)
	}
	defer func() {
		db.Close(ctx)
		os.RemoveAll("./fulltext-demo.db")
	}()

	// å®šä¹‰æ–‡ç« é›†åˆçš„ schema
	schema := rxdb.Schema{
		PrimaryKey: "id",
		RevField:   "_rev",
		JSON: map[string]any{
			"title":       "article",
			"description": "æ–‡ç« é›†åˆ",
			"version":     0,
			"type":        "object",
			"properties": map[string]any{
				"id":      map[string]any{"type": "string"},
				"title":   map[string]any{"type": "string"},
				"content": map[string]any{"type": "string"},
				"author":  map[string]any{"type": "string"},
				"tags":    map[string]any{"type": "array", "items": map[string]any{"type": "string"}},
			},
			"required": []string{"id", "title", "content"},
		},
	}

	// åˆ›å»ºé›†åˆ
	collection, err := db.Collection(ctx, "articles", schema)
	if err != nil {
		log.Fatalf("Failed to create collection: %v", err)
	}

	// æ’å…¥ç¤ºä¾‹æ–‡ç« 
	articles := []map[string]any{
		{
			"id":      "article-001",
			"title":   "Go è¯­è¨€å…¥é—¨æŒ‡å—",
			"content": "Go æ˜¯ä¸€ç§é™æ€ç±»å‹ã€ç¼–è¯‘å‹è¯­è¨€ï¼Œç”± Google å¼€å‘ã€‚å®ƒå…·æœ‰ç®€æ´çš„è¯­æ³•å’Œå¼ºå¤§çš„å¹¶å‘æ”¯æŒï¼Œéå¸¸é€‚åˆæ„å»ºé«˜æ€§èƒ½çš„æœåŠ¡ç«¯åº”ç”¨ç¨‹åºã€‚",
			"author":  "å¼ ä¸‰",
			"tags":    []string{"Go", "ç¼–ç¨‹", "å…¥é—¨"},
		},
		{
			"id":      "article-002",
			"title":   "æ·±å…¥ç†è§£ Go å¹¶å‘ç¼–ç¨‹",
			"content": "Go çš„ goroutine å’Œ channel æ˜¯å…¶å¹¶å‘æ¨¡å‹çš„æ ¸å¿ƒã€‚é€šè¿‡ goroutine å¯ä»¥è½»æ¾åˆ›å»ºè½»é‡çº§çº¿ç¨‹ï¼Œè€Œ channel åˆ™æä¾›äº†å®‰å…¨çš„é€šä¿¡æ–¹å¼ã€‚",
			"author":  "æå››",
			"tags":    []string{"Go", "å¹¶å‘", "é«˜çº§"},
		},
		{
			"id":      "article-003",
			"title":   "Python æœºå™¨å­¦ä¹ å®æˆ˜",
			"content": "Python æ˜¯æ•°æ®ç§‘å­¦å’Œæœºå™¨å­¦ä¹ çš„é¦–é€‰è¯­è¨€ã€‚æœ¬æ–‡ä»‹ç»å¦‚ä½•ä½¿ç”¨ scikit-learn å’Œ TensorFlow æ„å»ºæœºå™¨å­¦ä¹ æ¨¡å‹ã€‚",
			"author":  "ç‹äº”",
			"tags":    []string{"Python", "æœºå™¨å­¦ä¹ ", "AI"},
		},
		{
			"id":      "article-004",
			"title":   "JavaScript å‰ç«¯æ¡†æ¶å¯¹æ¯”",
			"content": "Reactã€Vue å’Œ Angular æ˜¯ç›®å‰æœ€æµè¡Œçš„å‰ç«¯æ¡†æ¶ã€‚æœ¬æ–‡å°†ä»æ€§èƒ½ã€å­¦ä¹ æ›²çº¿å’Œç”Ÿæ€ç³»ç»Ÿç­‰æ–¹é¢è¿›è¡Œè¯¦ç»†å¯¹æ¯”ã€‚",
			"author":  "èµµå…­",
			"tags":    []string{"JavaScript", "å‰ç«¯", "æ¡†æ¶"},
		},
		{
			"id":      "article-005",
			"title":   "Go å¾®æœåŠ¡æ¶æ„è®¾è®¡",
			"content": "å¾®æœåŠ¡æ¶æ„å·²æˆä¸ºç°ä»£åº”ç”¨å¼€å‘çš„ä¸»æµæ¨¡å¼ã€‚Go è¯­è¨€å‡­å€Ÿå…¶å‡ºè‰²çš„æ€§èƒ½å’Œç®€å•çš„éƒ¨ç½²æ–¹å¼ï¼Œæˆä¸ºå¾®æœåŠ¡å¼€å‘çš„çƒ­é—¨é€‰æ‹©ã€‚",
			"author":  "å¼ ä¸‰",
			"tags":    []string{"Go", "å¾®æœåŠ¡", "æ¶æ„"},
		},
	}

	fmt.Println("ğŸ“š æ’å…¥ç¤ºä¾‹æ–‡ç« ...")
	for i, article := range articles {
		fmt.Printf("  æ­£åœ¨æ’å…¥ç¬¬ %d/%d ç¯‡æ–‡ç« : %s\n", i+1, len(articles), article["id"])
		_, err := collection.Insert(ctx, article)
		if err != nil {
			log.Printf("Failed to insert article %s: %v", article["id"], err)
		} else {
			fmt.Printf("  âœ… æˆåŠŸæ’å…¥: %s\n", article["id"])
		}
	}
	fmt.Printf("âœ… å·²æ’å…¥ %d ç¯‡æ–‡ç« \n\n", len(articles))

	// ========================================
	// åˆ›å»ºå…¨æ–‡æœç´¢å®ä¾‹
	// ========================================
	fmt.Println("ğŸ” åˆ›å»ºå…¨æ–‡æœç´¢ç´¢å¼•...")
	fts, err := rxdb.AddFulltextSearch(collection, rxdb.FulltextSearchConfig{
		Identifier: "article-search",
		// DocToString å®šä¹‰å¦‚ä½•å°†æ–‡æ¡£è½¬æ¢ä¸ºå¯æœç´¢çš„å­—ç¬¦ä¸²
		DocToString: func(doc map[string]any) string {
			title, _ := doc["title"].(string)
			content, _ := doc["content"].(string)
			author, _ := doc["author"].(string)
			// åˆå¹¶æ ‡é¢˜ã€å†…å®¹å’Œä½œè€…ï¼Œæ ‡é¢˜æƒé‡æ›´é«˜ï¼ˆé‡å¤ä»¥å¢åŠ æƒé‡ï¼‰
			return title + " " + title + " " + content + " " + author
		},
		// ç´¢å¼•é€‰é¡¹
		IndexOptions: &rxdb.FulltextIndexOptions{
			Tokenize:      "forward",                              // æ”¯æŒå‰ç¼€åŒ¹é…
			MinLength:     2,                                      // æœ€å°è¯é•¿åº¦
			CaseSensitive: false,                                  // ä¸åŒºåˆ†å¤§å°å†™
			StopWords:     []string{"çš„", "æ˜¯", "å’Œ", "äº†", "åœ¨", "æœ‰"}, // ä¸­æ–‡åœç”¨è¯
		},
	})
	if err != nil {
		log.Fatalf("Failed to create fulltext search: %v", err)
	}
	defer fts.Close()
	fmt.Printf("âœ… ç´¢å¼•åˆ›å»ºå®Œæˆï¼Œå·²ç´¢å¼• %d ç¯‡æ–‡ç« \n\n", fts.Count())

	// ========================================
	// æ‰§è¡Œæœç´¢ç¤ºä¾‹
	// ========================================

	// ç¤ºä¾‹ 1: æœç´¢ "Go"
	fmt.Println("=" + "===========================================")
	fmt.Println("ğŸ” æœç´¢: \"Go\"")
	fmt.Println("===========================================")
	results, err := fts.Find(ctx, "Go")
	if err != nil {
		log.Fatalf("Search failed: %v", err)
	}
	fmt.Printf("æ‰¾åˆ° %d ç¯‡ç›¸å…³æ–‡ç« :\n", len(results))
	for _, doc := range results {
		fmt.Printf("  ğŸ“„ [%s] %s - %s\n", doc.ID(), doc.Data()["title"], doc.Data()["author"])
	}
	fmt.Println()

	// ç¤ºä¾‹ 2: æœç´¢ "å¹¶å‘"
	fmt.Println("===========================================")
	fmt.Println("ğŸ” æœç´¢: \"å¹¶å‘\"")
	fmt.Println("===========================================")
	results, err = fts.Find(ctx, "å¹¶å‘")
	if err != nil {
		log.Fatalf("Search failed: %v", err)
	}
	fmt.Printf("æ‰¾åˆ° %d ç¯‡ç›¸å…³æ–‡ç« :\n", len(results))
	for _, doc := range results {
		fmt.Printf("  ğŸ“„ [%s] %s\n", doc.ID(), doc.Data()["title"])
	}
	fmt.Println()

	// ç¤ºä¾‹ 3: æœç´¢ "æœºå™¨å­¦ä¹ " å¹¶è¿”å›å¸¦åˆ†æ•°çš„ç»“æœ
	fmt.Println("===========================================")
	fmt.Println("ğŸ” æœç´¢: \"æœºå™¨å­¦ä¹ \" (å¸¦ç›¸å…³æ€§åˆ†æ•°)")
	fmt.Println("===========================================")
	resultsWithScores, err := fts.FindWithScores(ctx, "æœºå™¨å­¦ä¹ ")
	if err != nil {
		log.Fatalf("Search failed: %v", err)
	}
	fmt.Printf("æ‰¾åˆ° %d ç¯‡ç›¸å…³æ–‡ç« :\n", len(resultsWithScores))
	for _, r := range resultsWithScores {
		fmt.Printf("  ğŸ“„ [åˆ†æ•°: %.2f] %s\n", r.Score, r.Document.Data()["title"])
	}
	fmt.Println()

	// ç¤ºä¾‹ 4: å¤šè¯æœç´¢
	fmt.Println("===========================================")
	fmt.Println("ğŸ” æœç´¢: \"Go å¾®æœåŠ¡\"")
	fmt.Println("===========================================")
	results, err = fts.Find(ctx, "Go å¾®æœåŠ¡")
	if err != nil {
		log.Fatalf("Search failed: %v", err)
	}
	fmt.Printf("æ‰¾åˆ° %d ç¯‡ç›¸å…³æ–‡ç« :\n", len(results))
	for _, doc := range results {
		fmt.Printf("  ğŸ“„ [%s] %s\n", doc.ID(), doc.Data()["title"])
	}
	fmt.Println()

	// ç¤ºä¾‹ 5: å¸¦é™åˆ¶çš„æœç´¢
	fmt.Println("===========================================")
	fmt.Println("ğŸ” æœç´¢: \"è¯­è¨€\" (é™åˆ¶è¿”å› 2 æ¡)")
	fmt.Println("===========================================")
	results, err = fts.Find(ctx, "è¯­è¨€", rxdb.FulltextSearchOptions{
		Limit: 2,
	})
	if err != nil {
		log.Fatalf("Search failed: %v", err)
	}
	fmt.Printf("æ‰¾åˆ° %d ç¯‡ç›¸å…³æ–‡ç«  (é™åˆ¶ 2 æ¡):\n", len(results))
	for _, doc := range results {
		fmt.Printf("  ğŸ“„ [%s] %s\n", doc.ID(), doc.Data()["title"])
	}
	fmt.Println()

	// ç¤ºä¾‹ 6: å‰ç¼€åŒ¹é…æœç´¢ï¼ˆåˆ©ç”¨ forward tokenize æ¨¡å¼ï¼‰
	// æ³¨æ„ï¼šç”±äºé…ç½®äº† Tokenize: "forward"ï¼Œæœç´¢ "Go" ä¼šåŒ¹é…æ‰€æœ‰ä»¥ "Go" å¼€å¤´çš„è¯
	fmt.Println("===========================================")
	fmt.Println("ğŸ” å‰ç¼€åŒ¹é…æœç´¢: \"Go\" (forward æ¨¡å¼æ”¯æŒå‰ç¼€åŒ¹é…)")
	fmt.Println("===========================================")
	results, err = fts.Find(ctx, "Go")
	if err != nil {
		log.Fatalf("Search failed: %v", err)
	}
	fmt.Printf("æ‰¾åˆ° %d ç¯‡ç›¸å…³æ–‡ç«  (åŒ…å« \"Go\" æˆ–ä»¥å…¶å¼€å¤´çš„è¯):\n", len(results))
	for _, doc := range results {
		fmt.Printf("  ğŸ“„ [%s] %s\n", doc.ID(), doc.Data()["title"])
	}
	fmt.Println()

	// ç¤ºä¾‹ 7: å¤§å°å†™ä¸æ•æ„Ÿæœç´¢
	fmt.Println("===========================================")
	fmt.Println("ğŸ” å¤§å°å†™ä¸æ•æ„Ÿæœç´¢: \"python\" (å°å†™)")
	fmt.Println("===========================================")
	results, err = fts.Find(ctx, "python")
	if err != nil {
		log.Fatalf("Search failed: %v", err)
	}
	fmt.Printf("æ‰¾åˆ° %d ç¯‡ç›¸å…³æ–‡ç« :\n", len(results))
	for _, doc := range results {
		fmt.Printf("  ğŸ“„ [%s] %s\n", doc.ID(), doc.Data()["title"])
	}
	fmt.Println()

	// ç¤ºä¾‹ 8: ç©ºæŸ¥è¯¢å¤„ç†
	fmt.Println("===========================================")
	fmt.Println("ğŸ” ç©ºæŸ¥è¯¢æµ‹è¯•: \"\"")
	fmt.Println("===========================================")
	results, err = fts.Find(ctx, "")
	if err != nil {
		log.Fatalf("Search failed: %v", err)
	}
	fmt.Printf("æ‰¾åˆ° %d ç¯‡ç›¸å…³æ–‡ç«  (ç©ºæŸ¥è¯¢åº”è¿”å›ç©ºç»“æœ):\n", len(results))
	fmt.Println()

	// ç¤ºä¾‹ 9: ä¸å­˜åœ¨çš„å…³é”®è¯
	fmt.Println("===========================================")
	fmt.Println("ğŸ” ä¸å­˜åœ¨çš„å…³é”®è¯: \"ä¸å­˜åœ¨çš„å†…å®¹\"")
	fmt.Println("===========================================")
	results, err = fts.Find(ctx, "ä¸å­˜åœ¨çš„å†…å®¹")
	if err != nil {
		log.Fatalf("Search failed: %v", err)
	}
	fmt.Printf("æ‰¾åˆ° %d ç¯‡ç›¸å…³æ–‡ç«  (åº”è¯¥ä¸º 0):\n", len(results))
	fmt.Println()

	// ç¤ºä¾‹ 10: åœç”¨è¯è¿‡æ»¤æµ‹è¯•
	fmt.Println("===========================================")
	fmt.Println("ğŸ” åœç”¨è¯æµ‹è¯•: \"çš„\" (åº”è¯¥è¢«è¿‡æ»¤)")
	fmt.Println("===========================================")
	results, err = fts.Find(ctx, "çš„")
	if err != nil {
		log.Fatalf("Search failed: %v", err)
	}
	fmt.Printf("æ‰¾åˆ° %d ç¯‡ç›¸å…³æ–‡ç«  (åœç”¨è¯åº”è¿”å›ç©ºç»“æœ):\n", len(results))
	fmt.Println()

	// ç¤ºä¾‹ 11: ç›¸å…³æ€§é˜ˆå€¼è¿‡æ»¤
	fmt.Println("===========================================")
	fmt.Println("ğŸ” ç›¸å…³æ€§é˜ˆå€¼è¿‡æ»¤: \"Go\" (é˜ˆå€¼ 5.0)")
	fmt.Println("===========================================")
	results, err = fts.Find(ctx, "Go", rxdb.FulltextSearchOptions{
		Threshold: 5.0,
	})
	if err != nil {
		log.Fatalf("Search failed: %v", err)
	}
	fmt.Printf("æ‰¾åˆ° %d ç¯‡ç›¸å…³æ–‡ç«  (åˆ†æ•° >= 5.0):\n", len(results))
	resultsWithScores, _ = fts.FindWithScores(ctx, "Go")
	for _, r := range resultsWithScores {
		if r.Score >= 5.0 {
			fmt.Printf("  ğŸ“„ [åˆ†æ•°: %.2f] %s\n", r.Score, r.Document.Data()["title"])
		}
	}
	fmt.Println()

	// ç¤ºä¾‹ 12: ä¸­æ–‡åˆ†è¯æµ‹è¯•
	fmt.Println("===========================================")
	fmt.Println("ğŸ” ä¸­æ–‡åˆ†è¯æµ‹è¯•: \"ç¼–ç¨‹\"")
	fmt.Println("===========================================")
	results, err = fts.Find(ctx, "ç¼–ç¨‹")
	if err != nil {
		log.Fatalf("Search failed: %v", err)
	}
	fmt.Printf("æ‰¾åˆ° %d ç¯‡ç›¸å…³æ–‡ç« :\n", len(results))
	for _, doc := range results {
		fmt.Printf("  ğŸ“„ [%s] %s\n", doc.ID(), doc.Data()["title"])
	}
	fmt.Println()

	// ç¤ºä¾‹ 13: æ•°å­—æœç´¢æµ‹è¯•
	fmt.Println("===========================================")
	fmt.Println("ğŸ” æ•°å­—æœç´¢æµ‹è¯•: \"001\"")
	fmt.Println("===========================================")
	results, err = fts.Find(ctx, "001")
	if err != nil {
		log.Fatalf("Search failed: %v", err)
	}
	fmt.Printf("æ‰¾åˆ° %d ç¯‡ç›¸å…³æ–‡ç«  (é€šè¿‡æ–‡æ¡£IDåŒ¹é…):\n", len(results))
	for _, doc := range results {
		fmt.Printf("  ğŸ“„ [%s] %s\n", doc.ID(), doc.Data()["title"])
	}
	fmt.Println()

	// ç¤ºä¾‹ 14: ç»„åˆæœç´¢ï¼ˆå¤šä¸ªå…³é”®è¯ï¼‰
	fmt.Println("===========================================")
	fmt.Println("ğŸ” ç»„åˆæœç´¢: \"Go å¹¶å‘ ç¼–ç¨‹\"")
	fmt.Println("===========================================")
	results, err = fts.Find(ctx, "Go å¹¶å‘ ç¼–ç¨‹")
	if err != nil {
		log.Fatalf("Search failed: %v", err)
	}
	fmt.Printf("æ‰¾åˆ° %d ç¯‡ç›¸å…³æ–‡ç«  (åŒ…å«å¤šä¸ªå…³é”®è¯):\n", len(results))
	for _, doc := range results {
		fmt.Printf("  ğŸ“„ [%s] %s\n", doc.ID(), doc.Data()["title"])
	}
	fmt.Println()

	// ç¤ºä¾‹ 15: çŸ­è¯æœç´¢ï¼ˆæµ‹è¯•æœ€å°é•¿åº¦é™åˆ¶ï¼‰
	fmt.Println("===========================================")
	fmt.Println("ğŸ” çŸ­è¯æœç´¢: \"G\" (é•¿åº¦å°äº MinLength=2)")
	fmt.Println("===========================================")
	results, err = fts.Find(ctx, "G")
	if err != nil {
		log.Fatalf("Search failed: %v", err)
	}
	fmt.Printf("æ‰¾åˆ° %d ç¯‡ç›¸å…³æ–‡ç«  (çŸ­è¯åº”è¢«è¿‡æ»¤):\n", len(results))
	fmt.Println()

	// ========================================
	// å®æ—¶ç´¢å¼•æ›´æ–°ç¤ºä¾‹
	// ========================================
	fmt.Println("===========================================")
	fmt.Println("ğŸ“ å®æ—¶ç´¢å¼•æ›´æ–°æµ‹è¯•")
	fmt.Println("===========================================")

	// æ’å…¥æ–°æ–‡ç« 
	fmt.Println("æ’å…¥æ–°æ–‡ç« : \"Rust ç³»ç»Ÿç¼–ç¨‹\"...")
	_, err = collection.Insert(ctx, map[string]any{
		"id":      "article-006",
		"title":   "Rust ç³»ç»Ÿç¼–ç¨‹å…¥é—¨",
		"content": "Rust æ˜¯ä¸€ç§ç³»ç»Ÿç¼–ç¨‹è¯­è¨€ï¼Œä¸“æ³¨äºå®‰å…¨æ€§ã€é€Ÿåº¦å’Œå¹¶å‘æ€§ã€‚å®ƒé€šè¿‡æ‰€æœ‰æƒç³»ç»Ÿå®ç°å†…å­˜å®‰å…¨ã€‚",
		"author":  "å‘¨ä¸ƒ",
		"tags":    []string{"Rust", "ç³»ç»Ÿç¼–ç¨‹", "å®‰å…¨"},
	})
	if err != nil {
		log.Printf("Insert failed: %v", err)
	}

	// æ‰‹åŠ¨é‡å»ºç´¢å¼•ä»¥åŒ…å«æ–°æ–‡æ¡£ï¼ˆå®é™…åº”ç”¨ä¸­ä¼šè‡ªåŠ¨æ›´æ–°ï¼‰
	fts.Reindex(ctx)

	// æœç´¢æ–°æ–‡ç« 
	fmt.Println("æœç´¢ \"ç³»ç»Ÿ\"...")
	results, _ = fts.Find(ctx, "ç³»ç»Ÿ")
	fmt.Printf("æ‰¾åˆ° %d ç¯‡ç›¸å…³æ–‡ç« :\n", len(results))
	for _, doc := range results {
		fmt.Printf("  ğŸ“„ [%s] %s\n", doc.ID(), doc.Data()["title"])
	}
	fmt.Println()

	// ========================================
	// æŒä¹…åŒ–ç´¢å¼•ç¤ºä¾‹
	// ========================================
	fmt.Println("===========================================")
	fmt.Println("ğŸ’¾ æŒä¹…åŒ–ç´¢å¼•")
	fmt.Println("===========================================")
	err = fts.Persist(ctx)
	if err != nil {
		log.Printf("Failed to persist index: %v", err)
	} else {
		fmt.Println("âœ… ç´¢å¼•å·²æŒä¹…åŒ–åˆ°å­˜å‚¨")
	}
	fmt.Println()

	fmt.Println("ğŸ‰ å…¨æ–‡æœç´¢æ¼”ç¤ºå®Œæˆ!")
}
